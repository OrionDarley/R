
#Orion Darley

##########################################
#Exercise 8 of Section 8.4 of ISLR.
##########################################

#8. In the lab, a classification tree was applied to the Carseats data set after
#converting Sales into a qualitative response variable. Now we will
#seek to predict Sales using regression trees and related approaches,
#treating the response as a quantitative variable.



#(a) Split the data set into a training set and a test set.



#(b) Fit a regression tree to the training set. Plot the tree, and interpret
#the results. What test MSE do you obtain?



#(c) Use cross-validation in order to determine the optimal level of
#tree complexity. Does pruning the tree improve the test MSE?



#(d) Use the bagging approach in order to analyze this data. What
#test MSE do you obtain? Use the importance() function to determine
#which variables are most important.



#(e) Use random forests to analyze this data. What test MSE do you
#obtain? Use the importance() function to determine which variables
#aremost important. Describe the effect of m, the number of
#variables considered at each split, on the error rate
#obtained.

##########################################
#Exercise 9 of Section 8.4 of ISLR.
##########################################

#9. This problem involves the OJ data set which is part of the ISLR
#package.



#(a) Create a training set containing a random sample of 800 observations,
#and a test set containing the remaining observations.



#(b) Fit a tree to the training data, with Purchase as the response
#and the other variables as predictors. Use the summary() function
#to produce summary statistics about the tree, and describe the
#results obtained. What is the training error rate? How many
#terminal nodes does the tree have?



#(c) Type in the name of the tree object in order to get a detailed
#text output. Pick one of the terminal nodes, and interpret the
#information displayed.



#(d) Create a plot of the tree, and interpret the results.



#(e) Predict the response on the test data, and produce a confusion
#matrix comparing the test labels to the predicted test labels.
#What is the test error rate?



#(f) Apply the cv.tree() function to the training set in order to
#determine the optimal tree size.



#(g) Produce a plot with tree size on the x-axis and cross-validated
#classification error rate on the y-axis.



#(h) Which tree size corresponds to the lowest cross-validated classification
#error rate?



#(i) Produce a pruned tree corresponding to the optimal tree size
#obtained using cross-validation. If cross-validation does not lead
#to selection of a pruned tree, then create a pruned tree with five
#terminal nodes.



#(j) Compare the training error rates between the pruned and unpruned
#trees. Which is higher?



#(k) Compare the test error rates between the pruned and unpruned
#trees. Which is higher?

##########################################
#Exercise 9 of Section 10.7 of ISLR.
##########################################

#9. Consider the USArrests data. We will now perform hierarchical clustering
#on the states.



#(a) Using hierarchical clustering with complete linkage and
#Euclidean distance, cluster the states.



#(b) Cut the dendrogram at a height that results in three distinct
#clusters. Which states belong to which clusters?



#(c) Hierarchically cluster the states using complete linkage and Euclidean
#distance, after scaling the variables to have standard deviation one.



#(d) What effect does scaling the variables have on the hierarchical
#clustering obtained? In your opinion, should the variables be
#scaled before the inter-observation dissimilarities are computed?
#Provide a justification for your answer.

##########################################
#Exercise 10 of Section 10.7 of ISLR.
##########################################

#10. In this problem, you will generate simulated data, and then perform
#PCA and K-means clustering on the data.



#a) Generate a simulated data set with 20 observations in each of
#three classes (i.e. 60 observations total), and 50 variables.
#Hint: There are a number of functions in R that you can use to
#generate data. One example is the rnorm() function; runif() is
#another option. Be sure to add a mean shift to the observations
#in each class so that there are three distinct classes.



#(b) Perform PCA on the 60 observations and plot the first two principal
#component score vectors. Use a different color to indicate
#the observations in each of the three classes. If the three classes
#appear separated in this plot, then continue on to part (c). If
#not, then return to part (a) and modify the simulation so that
#there is greater separation between the three classes. Do not
#continue to part (c) until the three classes show at least some
#separation in the first two principal component score vectors.



#(c) Perform K-means clustering of the observations with K = 3.
#How well do the clusters that you obtained in K-means clustering
#compare to the true class labels?
#Hint: You can use the table() function in R to compare the true
#class labels to the class labels obtained by clustering. Be careful
#how you interpret the results: K-means clustering will arbitrarily
#number the clusters, so you cannot simply check whether the true
#class labels and clustering labels are the same.



#(d) Perform K-means clustering with K = 2. Describe your results.



#(e) Now perform K-means clustering with K = 4, and describe your
#results.



#(f) Now perform K-means clustering with K = 3 on the first two
#principal component score vectors, rather than on the raw data.
#That is, perform K-means clustering on the 60 Ã— 2 matrix of
#which the first column is the first principal component score
#vector, and the second column is the second principal component
#score vector. Comment on the results.



#(g) Using the scale() function, perform K-means clustering with
#K = 3 on the data after scaling each variable to have standard
#deviation one. How do these results compare to those obtained
#in (b)? Explain.
